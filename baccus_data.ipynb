{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from openretina.dataloaders import get_movie_dataloader\n",
    "from openretina.hoefling_2022_data_io import gen_start_indices, natmov_dataloaders_v2\n",
    "from openretina.hoefling_2022_models import SFB3d_core_SxF3d_readout\n",
    "from openretina.misc import (\n",
    "    CustomPrettyPrinter,\n",
    "    load_dataset_from_h5,\n",
    "    print_h5_structure,\n",
    ")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_folder = Path(\"~/PhD_data\").expanduser()\n",
    "base_folder = Path(\"/Data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = CustomPrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /Data/baccus_data/neural_code_data/ganglion_cell_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baccus_data_example_path = os.path.join(\n",
    "    base_folder,\n",
    "    \"baccus_data/neural_code_data/ganglion_cell_data/15-10-07/naturalscene.h5\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_h5_structure(baccus_data_example_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_video_baccus = load_dataset_from_h5(baccus_data_example_path, \"/train/stimulus\")\n",
    "test_video_baccus = load_dataset_from_h5(baccus_data_example_path, \"/test/stimulus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baccus_data_example_path_2 = os.path.join(\n",
    "    base_folder,\n",
    "    \"baccus_data/neural_code_data/ganglion_cell_data/15-11-21b/naturalscene.h5\",\n",
    ")\n",
    "train_video_baccus_2 = load_dataset_from_h5(\n",
    "    baccus_data_example_path_2, \"/train/stimulus\"\n",
    ")\n",
    "test_video_baccus_2 = load_dataset_from_h5(baccus_data_example_path_2, \"/test/stimulus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_video_baccus = train_video_baccus[None, :]\n",
    "train_video_baccus.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding the stimuli used:\n",
    "\n",
    "    A video monitor projected the visual stimuli at 30 Hz controlled by Matlab (Mathworks), using Psychophysics Toolbox.54 Stimuli had a constant mean intensity of 10 mW/m2. Images were presented in a 50 x 50 grid with a square size of 50 mm. Static natural jittered scenes consisted of images drawn from a natural image database.55 To create images for presentation to the retina, original color images were converted to grayscale, and were scaled to have minimum and maximum pixel intensities that matched that of the monitor. Pixel regions of 50 x 50 size were then selected from each image at a random location without spatial averaging for presentation.\n",
    "    \n",
    "So it is natural images, not videos. Also, regarding stimulus presentation:\n",
    "\n",
    "    The image also abruptly changed in a single frame to a different location every one second, representing saccades, although such transitions did not contain a sweeping shift in the image. Transitions occurred both between different locations in the same image and between different images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openretina.plotting import play_stimulus\n",
    "\n",
    "play_stimulus(torch.Tensor(train_video_baccus[:, :90]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_response_baccus = load_dataset_from_h5(baccus_data_example_path, \"/train/response/firing_rate_20ms\")\n",
    "test_response_baccus = load_dataset_from_h5(baccus_data_example_path, \"/test/response/firing_rate_20ms\")\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 2))\n",
    "plt.plot(train_response_baccus[8, :300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single \"clip\" length is 90 frames. (i.e. how long an image was shown for)\n",
    "\n",
    "Response should be firing rate in Hz, calculated from the ephys trace with various time bins. In the paper they say to train the model \"The response and stimulus were binned in 10 ms time bins.\"\n",
    "\n",
    "Our response is also a firing rate, but inferred from the calcium trace using c2s. Given that they are using MEAs, the temporal resolution of the signal (and some of the binning they used) is much higher. \n",
    "\n",
    "However, we can still use the spikes they provided to get a similar binning to our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Sample data input and model training on Salamander data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_length = train_video_baccus.shape[1]\n",
    "clip_length = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataloader = get_movie_dataloader(\n",
    "    train_video_baccus,\n",
    "    train_response_baccus.T,  # Transpose the response to match the dataloader format\n",
    "    roi_ids=np.arange(train_response_baccus.shape[0]),\n",
    "    roi_coords=np.random.normal(0, 1, (train_response_baccus.shape[0], 2)),\n",
    "    group_assignment=np.arange(train_response_baccus.shape[0]),\n",
    "    split=\"train\",\n",
    "    start_indices=np.arange(0, train_video_baccus.shape[1], 90),\n",
    "    scan_sequence_idx=None,\n",
    "    chunk_size=60,\n",
    "    batch_size=32,\n",
    "    scene_length=90,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalising_fr = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baccus_data_dict = {\n",
    "    \"test_session\": {\n",
    "        \"responses_final\": {\n",
    "            \"train\": train_response_baccus / normalising_fr,\n",
    "            \"test\": test_response_baccus / normalising_fr,\n",
    "        },\n",
    "        \"stim_id\": \"salamander_natural\",\n",
    "    }\n",
    "}\n",
    "baccus_movie_dict = {\"train\": train_video_baccus, \"test\": test_video_baccus[None, ...]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openretina.maheswaranathan_2023_data_io import load_all_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses, stimuli = load_all_sessions(\n",
    "    os.path.join(base_folder, \"baccus_data/neural_code_data/ganglion_cell_data/\"), fr_normalization=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = natmov_dataloaders_v2(\n",
    "    responses,\n",
    "    stimuli,\n",
    "    train_chunk_size=50,\n",
    "    batch_size=32,\n",
    "    clip_length=90,\n",
    "    num_clips=len(np.arange(0, movie_length // clip_length)),\n",
    "    num_val_clips=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openretina.hoefling_2022_configs import model_config\n",
    "\n",
    "model = SFB3d_core_SxF3d_readout(**model_config, dataloaders=dataloaders, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openretina.hoefling_2022_configs import trainer_config\n",
    "from openretina.training import standard_early_stop_trainer\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()\n",
    "run = wandb.init(\n",
    "    project=\"salamander_data_hoefling_2022_model\",\n",
    "    notes=\"First tests with mouse architecture on salamander image data.\",\n",
    "    tags=None,\n",
    "    job_type=None,\n",
    "    name=None,\n",
    ")\n",
    "\n",
    "wandb.config.update({**model_config, **trainer_config})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score, val_score, output, model_state = standard_early_stop_trainer(\n",
    "    model,\n",
    "    dataloaders,\n",
    "    max_epochs=1,\n",
    "    seed=42,\n",
    "    device=\"cuda\",\n",
    "    wandb_logger=run,\n",
    "    **trainer_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_field = \"15-10-07\"\n",
    "val_sample = next(iter(dataloaders[\"validation\"][val_field]))\n",
    "\n",
    "input_samples = val_sample.inputs\n",
    "targets = val_sample.targets\n",
    "\n",
    "model.eval()\n",
    "model.cpu()\n",
    "\n",
    "with torch.no_grad():\n",
    "    reconstructions = model(input_samples.cpu(), val_field)\n",
    "reconstructions = reconstructions.cpu().numpy().squeeze()\n",
    "\n",
    "targets = targets.cpu().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "neuron = 1\n",
    "fig, axes = plt.subplots(4, 5, figsize=(20, 5), sharey=\"row\", sharex=\"col\")\n",
    "for trace_chunk in range(targets.shape[0]):\n",
    "    ax_idx_1 = trace_chunk // 5\n",
    "    ax_idx_2 = trace_chunk % 5\n",
    "    ax = axes[ax_idx_1, ax_idx_2]\n",
    "    ax.plot(targets[trace_chunk, 30:, neuron], label=\"target\")\n",
    "    ax.plot(reconstructions[trace_chunk, :, neuron], label=\"prediction\")\n",
    "\n",
    "    # Set x and y labels for only outer subplots\n",
    "    if ax_idx_1 == 2:  # Bottom row\n",
    "        ax.set_xlabel(\"Frames\")\n",
    "    if ax_idx_2 == 0:  # Leftmost column\n",
    "        ax.set_ylabel(\"Firing rate\")\n",
    "\n",
    "    # # Remove inner labels\n",
    "    # if ax_idx_1 != 2:\n",
    "    #     ax.set_xticklabels([])\n",
    "    # if ax_idx_2 != 0:\n",
    "    #     ax.set_yticklabels([])\n",
    "    # Only turn on x-axis labels for the bottom row\n",
    "    if ax_idx_1 == 2:\n",
    "        ax.tick_params(labelbottom=True)\n",
    "    else:\n",
    "        ax.tick_params(labelbottom=False)\n",
    "\n",
    "    # Only turn on y-axis labels for the leftmost column\n",
    "    if ax_idx_2 == 0:\n",
    "        ax.tick_params(labelleft=True)\n",
    "    else:\n",
    "        ax.tick_params(labelleft=False)\n",
    "\n",
    "# Place the legend outside of the subplots\n",
    "axes[0, 0].legend()\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "wandb.log({\"reconstruction\": fig})\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_field = \"15-10-07\"\n",
    "test_sample = next(iter(dataloaders[\"test\"][test_field]))\n",
    "\n",
    "input_samples = test_sample.inputs\n",
    "targets = test_sample.targets\n",
    "\n",
    "model.eval()\n",
    "model.cpu()\n",
    "\n",
    "with torch.no_grad():\n",
    "    reconstructions = model(input_samples.cpu(), test_field)\n",
    "reconstructions = reconstructions.cpu().numpy().squeeze()\n",
    "\n",
    "targets = targets.cpu().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 500\n",
    "neuron = 2\n",
    "plt.plot(np.arange(0, window), targets[:window, neuron], label=\"target\")\n",
    "plt.plot(np.arange(30, window + 30), reconstructions[:window, neuron], label=\"prediction\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
