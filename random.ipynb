{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "from typing import List, Optional, Tuple\n",
    "\n",
    "import h5py as h5\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from openretina.constants import CLIP_LENGTH, NUM_CLIPS, NUM_VAL_CLIPS\n",
    "from openretina.dataloaders import get_movie_dataloader\n",
    "from openretina.misc import CustomPrettyPrinter\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"/Data/fd_export\"\n",
    "data_path = os.path.join(base_folder, \"2024-01-11_neuron_data_stim_8c18928_responses_99c71a0.pkl\")\n",
    "movies_path = os.path.join(base_folder, \"2024-01-11_movies_dict_8c18928.pkl\")\n",
    "old_movies_path = os.path.join(base_folder, \"movies_8c18928.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open(data_path, \"rb\"))\n",
    "movies = pickle.load(open(movies_path, \"rb\"))\n",
    "\n",
    "old_movies = pickle.load(open(old_movies_path, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   '1_ventral1_20210929': {   'eye': 'left',\n",
      "                               'group_assignment': numpy.ndarray(shape=(86,)),\n",
      "                               'key': {   'date': '2021-09-29',\n",
      "                                          'exp_num': 1,\n",
      "                                          'experimenter': 'Szatko',\n",
      "                                          'field_id': 1,\n",
      "                                          'stim_id': 5},\n",
      "                               'responses_final': numpy.ndarray(shape=(86, 18450)),\n",
      "                               'roi_coords': torch.Tensor(shape=[86, 2]),\n",
      "                               'roi_ids': numpy.ndarray(shape=(86,)),\n",
      "                               'scan_sequence_idx': 8,\n",
      "                               'stim_id': 5,\n",
      "                               'traces': numpy.ndarray(shape=(104,)),\n",
      "                               'tracestimes': numpy.ndarray(shape=(104,))},\n",
      "    '1_ventral1_20210930': {   'eye': 'left',\n",
      "                               'group_assignment': numpy.ndarray(shape=(69,)),\n",
      "                               'key': {   'date': '2021-09-30',\n",
      "                                          'exp_num': 1,\n",
      "                                          'experimenter': 'Szatko',\n",
      "                                          'field_id': 1,\n",
      "                                          'stim_id': 5},\n",
      "                               'responses_final': numpy.ndarray(shape=(69, 18450)),\n",
      "                               'roi_coords': torch.Tensor(shape=[69, 2]),\n",
      "                               'roi_ids': numpy.ndarray(shape=(69,)),\n",
      "                               'scan_sequence_idx': 5,\n",
      "                               'stim_id': 5,\n",
      "                               'traces': numpy.ndarray(shape=(108,)),\n",
      "                               'tracestimes': numpy.ndarray(shape=(108,))},\n",
      "    '1_ventral2_20210929': {   'eye': 'right',\n",
      "                               'group_assignment': numpy.ndarray(shape=(90,)),\n",
      "                               'key': {   'date': '2021-09-29',\n",
      "                                          'exp_num': 2,\n",
      "                                          'experimenter': 'Szatko',\n",
      "                                          'field_id': 1,\n",
      "                                          'stim_id': 5},\n",
      "                               'responses_final': numpy.ndarray(shape=(90, 18450)),\n",
      "                               'roi_coords': torch.Tensor(shape=[90, 2]),\n",
      "                               'roi_ids': numpy.ndarray(shape=(90,)),\n",
      "                               'scan_sequence_idx': 18,\n",
      "                               'stim_id': 5,\n",
      "                               'traces': numpy.ndarray(shape=(99,)),\n",
      "                               'tracestimes': numpy.ndarray(shape=(99,))},\n",
      "    '1_ventral2_20210930': {   'eye': 'right',\n",
      "                               'group_assignment': numpy.ndarray(shape=(103,)),\n",
      "                               'key': {   'date': '2021-09-30',\n",
      "                                          'exp_num': 2,\n",
      "                                          'experimenter': 'Szatko',\n",
      "                                          'field_id': 1,\n",
      "                                          'stim_id': 5},\n",
      "                               'responses_final': numpy.ndarray(shape=(103, 18450)),\n",
      "                               'roi_coords': torch.Tensor(shape=[103, 2]),\n",
      "                               'roi_ids': numpy.ndarray(shape=(103,)),\n",
      "                               'scan_sequence_idx': 7,\n",
      "                               'stim_id': 5,\n",
      "                               'traces': numpy.ndarray(shape=(113,)),\n",
      "                               'tracestimes': numpy.ndarray(shape=(113,))},\n",
      "    '2_ventral1_20210929': {   'eye': 'left',\n",
      "                               'group_assignment': numpy.ndarray(shape=(65,)),\n",
      "                               'key': {   'date': '2021-09-29',\n",
      "                                          'exp_num': 1,\n",
      "                                          'experimenter': 'Szatko',\n",
      "                                          'field_id': 2,\n",
      "                                          'stim_id': 5},\n",
      "                               'responses_final': numpy.ndarray(shape=(65, 18450)),\n",
      "                               'roi_coords': torch.Tensor(shape=[65, 2]),\n",
      "                               'roi_ids': numpy.ndarray(shape=(65,)),\n",
      "                               'scan_sequence_idx': 9,\n",
      "                               'stim_id': 5,\n",
      "                               'traces': numpy.ndarray(shape=(94,)),\n",
      "                               'tracestimes': numpy.ndarray(shape=(94,))},\n",
      "    '2_ventral2_20210929': {   'eye': 'right',\n",
      "                               'group_assignment': numpy.ndarray(shape=(95,)),\n",
      "                               'key': {   'date': '2021-09-29',\n",
      "                                          'exp_num': 2,\n",
      "                                          'experimenter': 'Szatko',\n",
      "                                          'field_id': 2,\n",
      "                                          'stim_id': 5},\n",
      "                               'responses_final': numpy.ndarray(shape=(95, 18450)),\n",
      "                               'roi_coords': torch.Tensor(shape=[95, 2]),\n",
      "                               'roi_ids': numpy.ndarray(shape=(95,)),\n",
      "                               'scan_sequence_idx': 19,\n",
      "                               'stim_id': 5,\n",
      "                               'traces': numpy.ndarray(shape=(117,)),\n",
      "                               'tracestimes': numpy.ndarray(shape=(117,))},\n",
      "    '2_ventral2_20210930': {   'eye': 'right',\n",
      "                               'group_assignment': numpy.ndarray(shape=(88,)),\n",
      "                               'key': {   'date': '2021-09-30',\n",
      "                                          'exp_num': 2,\n",
      "                                          'experimenter': 'Szatko',\n",
      "                                          'field_id': 2,\n",
      "                                          'stim_id': 5},\n",
      "                               'responses_final': numpy.ndarray(shape=(88, 18450)),\n",
      "                               'roi_coords': torch.Tensor(shape=[88, 2]),\n",
      "                               'roi_ids': numpy.ndarray(shape=(88,)),\n",
      "                               'scan_sequence_idx': 6,\n",
      "                               'stim_id': 5,\n",
      "                               'traces': numpy.ndarray(shape=(104,)),\n",
      "                               'tracestimes': numpy.ndarray(shape=(104,))},\n",
      "    '3_ventral2_20210929': {   'eye': 'right',\n",
      "                               'group_assignment': numpy.ndarray(shape=(115,)),\n",
      "                               'key': {   'date': '2021-09-29',\n",
      "                                          'exp_num': 2,\n",
      "                                          'experimenter': 'Szatko',\n",
      "                                          'field_id': 3,\n",
      "                                          'stim_id': 5},\n",
      "                               'responses_final': numpy.ndarray(shape=(115, 18450)),\n",
      "                               'roi_coords': torch.Tensor(shape=[115, 2]),\n",
      "                               'roi_ids': numpy.ndarray(shape=(115,)),\n",
      "                               'scan_sequence_idx': 8,\n",
      "                               'stim_id': 5,\n",
      "                               'traces': numpy.ndarray(shape=(134,)),\n",
      "                               'tracestimes': numpy.ndarray(shape=(134,))},\n",
      "    '3_ventral2_20210930': {   'eye': 'right',\n",
      "                               'group_assignment': numpy.ndarray(shape=(65,)),\n",
      "                               'key': {   'date': '2021-09-30',\n",
      "                                          'exp_num': 2,\n",
      "                                          'experimenter': 'Szatko',\n",
      "                                          'field_id': 3,\n",
      "                                          'stim_id': 5},\n",
      "                               'responses_final': numpy.ndarray(shape=(65, 18450)),\n",
      "                               'roi_coords': torch.Tensor(shape=[65, 2]),\n",
      "                               'roi_ids': numpy.ndarray(shape=(65,)),\n",
      "                               'scan_sequence_idx': 9,\n",
      "                               'stim_id': 5,\n",
      "                               'traces': numpy.ndarray(shape=(82,)),\n",
      "                               'tracestimes': numpy.ndarray(shape=(82,))},\n",
      "    '4_ventral2_20210929': {   'eye': 'right',\n",
      "                               'group_assignment': numpy.ndarray(shape=(77,)),\n",
      "                               'key': {   'date': '2021-09-29',\n",
      "                                          'exp_num': 2,\n",
      "                                          'experimenter': 'Szatko',\n",
      "                                          'field_id': 4,\n",
      "                                          'stim_id': 5},\n",
      "                               'responses_final': numpy.ndarray(shape=(77, 18450)),\n",
      "                               'roi_coords': torch.Tensor(shape=[77, 2]),\n",
      "                               'roi_ids': numpy.ndarray(shape=(77,)),\n",
      "                               'scan_sequence_idx': 9,\n",
      "                               'stim_id': 5,\n",
      "                               'traces': numpy.ndarray(shape=(94,)),\n",
      "                               'tracestimes': numpy.ndarray(shape=(94,))},\n",
      "    '5_ventral2_20210929': {   'eye': 'right',\n",
      "                               'group_assignment': numpy.ndarray(shape=(83,)),\n",
      "                               'key': {   'date': '2021-09-29',\n",
      "                                          'exp_num': 2,\n",
      "                                          'experimenter': 'Szatko',\n",
      "                                          'field_id': 5,\n",
      "                                          'stim_id': 5},\n",
      "                               'responses_final': numpy.ndarray(shape=(83, 18450)),\n",
      "                               'roi_coords': torch.Tensor(shape=[83, 2]),\n",
      "                               'roi_ids': numpy.ndarray(shape=(83,)),\n",
      "                               'scan_sequence_idx': 19,\n",
      "                               'stim_id': 5,\n",
      "                               'traces': numpy.ndarray(shape=(114,)),\n",
      "                               'tracestimes': numpy.ndarray(shape=(114,))}}\n",
      "{   'eye': 'right',\n",
      "    'random_sequences': numpy.ndarray(shape=(108, 20)),\n",
      "    'test': numpy.ndarray(shape=(2, 750, 18, 16)),\n",
      "    'train': numpy.ndarray(shape=(2, 16200, 18, 16))}\n"
     ]
    }
   ],
   "source": [
    "pp = CustomPrettyPrinter(indent=4)\n",
    "pp.pprint(data)\n",
    "pp.pprint(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_movie_combinations(\n",
    "    movie_train,\n",
    "    movie_test,\n",
    "    random_sequences: np.ndarray,\n",
    "    val_clip_idx: Optional[List[int]] = None,\n",
    "    seed=1000,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates combinations of movie data for 'left' and 'right' perspectives and\n",
    "    prepares training, validation, and test datasets. It reorders the training\n",
    "    movies based on random sequences and flips the movies for the 'left' perspective.\n",
    "\n",
    "    Parameters:\n",
    "    - movie_train: Tensor representing the training movie data.\n",
    "    - movie_test: Tensor representing the test movie data.\n",
    "    - random_sequences: Numpy array of random sequences for reordering training movies.\n",
    "    - val_clip_idx: list of indices for validation clips. Needs to be between 0 and the number of clips.\n",
    "    -seed: seed for random number generator, if val_clip_idx is None.\n",
    "\n",
    "    Returns:\n",
    "    - movies: Dictionary with processed movies for 'left' and 'right' perspectives, each\n",
    "      containing 'train', 'validation', and 'test' datasets.\n",
    "    \"\"\"\n",
    "    if val_clip_idx is None:\n",
    "        rnd = np.random.RandomState(seed)\n",
    "        val_clip_idx = list(rnd.choice(NUM_CLIPS, NUM_VAL_CLIPS, replace=False))\n",
    "\n",
    "    # Convert movie data to tensors\n",
    "    movie_train = torch.tensor(movie_train, dtype=torch.float)\n",
    "    movie_test = torch.tensor(movie_test, dtype=torch.float)\n",
    "\n",
    "    channels, train_length, px_y, px_x = movie_train.shape\n",
    "    clip_length = train_length // random_sequences.shape[0]\n",
    "\n",
    "    # Prepare validation movie data\n",
    "    movie_val = torch.zeros(\n",
    "        (channels, len(val_clip_idx) * clip_length, px_y, px_x), dtype=torch.float\n",
    "    )\n",
    "    for i, ind in enumerate(val_clip_idx):\n",
    "        movie_val[:, i * clip_length : (i + 1) * clip_length] = movie_train[\n",
    "            :, ind * clip_length : (ind + 1) * clip_length\n",
    "        ]\n",
    "\n",
    "    # Initialize movie dictionaries\n",
    "    movies = {\n",
    "        \"left\": {\n",
    "            \"train\": {},\n",
    "            \"validation\": torch.flip(movie_val, [-1]),\n",
    "            \"test\": torch.flip(movie_test, [-1]),\n",
    "        },\n",
    "        \"right\": {\"train\": {}, \"validation\": movie_val, \"test\": movie_test},\n",
    "    }\n",
    "\n",
    "    # Process training movies for each random sequence\n",
    "    for i in range(random_sequences.shape[1]):\n",
    "        reordered_movie = torch.zeros_like(movie_train)\n",
    "        for k, ind in enumerate(random_sequences[:, i]):\n",
    "            reordered_movie[:, k * clip_length : (k + 1) * clip_length] = movie_train[\n",
    "                :, ind * clip_length : (ind + 1) * clip_length\n",
    "            ]\n",
    "\n",
    "        movies[\"right\"][\"train\"][i] = reordered_movie\n",
    "        movies[\"left\"][\"train\"][i] = torch.flip(reordered_movie, [-1])\n",
    "\n",
    "    movies[\"val_clip_idx\"] = val_clip_idx\n",
    "\n",
    "    return movies\n",
    "\n",
    "\n",
    "def gen_start_indices(\n",
    "    random_sequences, val_clip_idx, clip_length, chunk_size, num_clips\n",
    "):  # 108 x 20 integer\n",
    "    \"\"\"\n",
    "    Generates a list of indices into movie frames that can be used as start\n",
    "    indices for training chunks without including validation clips in the\n",
    "    training set.\n",
    "\n",
    "    Args:\n",
    "        random_sequences (np.ndarray): Integer array of shape (108, 20) giving the ordering of the\n",
    "                                       108 training clips for the 20 different sequences.\n",
    "        val_clip_idx (list): List of integers indicating the 15 clips to be used for validation.\n",
    "        clip_length (int): Clip length in frames (5s * 30 frames/s = 150 frames).\n",
    "        chunk_size (int): Temporal chunk size per sample in frames (50).\n",
    "        num_clips (int): Total number of training clips (108).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with keys \"train\", \"validation\", and \"test\", and index lists as values.\n",
    "    \"\"\"\n",
    "    val_start_idx = list(\n",
    "        np.linspace(\n",
    "            0, clip_length * (len(val_clip_idx) - 1), len(val_clip_idx), dtype=int\n",
    "        )\n",
    "    )\n",
    "\n",
    "    start_idx_dict = {\"train\": {}, \"validation\": val_start_idx, \"test\": [0]}\n",
    "    for i in range(\n",
    "        random_sequences.shape[1]\n",
    "    ):  # iterate over the 20 different movie permutations\n",
    "        start_idx = 0\n",
    "        current_idx = 0\n",
    "        seq_start_idx = []\n",
    "        seq_length = []\n",
    "        for k, ind in enumerate(\n",
    "            random_sequences[: num_clips // 2, i]\n",
    "        ):  # over first half of the clips\n",
    "            if ind in val_clip_idx:\n",
    "                length = current_idx - start_idx\n",
    "                if length > 0:\n",
    "                    seq_start_idx.append(start_idx)\n",
    "                    seq_length.append(length)\n",
    "                start_idx = current_idx + clip_length\n",
    "            current_idx += clip_length\n",
    "        length = current_idx - start_idx\n",
    "        if length > 0:\n",
    "            seq_start_idx.append(start_idx)\n",
    "            seq_length.append(length)\n",
    "        start_idx = current_idx\n",
    "        for k, ind in enumerate(\n",
    "            random_sequences[num_clips // 2 :, i]\n",
    "        ):  # over second half of the clips\n",
    "            if ind in val_clip_idx:\n",
    "                length = current_idx - start_idx\n",
    "                if length > 0:\n",
    "                    seq_start_idx.append(start_idx)\n",
    "                    seq_length.append(length)\n",
    "                start_idx = current_idx + clip_length\n",
    "            current_idx += clip_length\n",
    "        length = current_idx - start_idx\n",
    "        if length > 0:\n",
    "            seq_start_idx.append(start_idx)\n",
    "            seq_length.append(length)\n",
    "\n",
    "        chunk_start_idx = []\n",
    "        for start, length in zip(seq_start_idx, seq_length):\n",
    "            idx = np.arange(start, start + length - chunk_size + 1, chunk_size)\n",
    "            chunk_start_idx += list(idx[:-1])\n",
    "        start_idx_dict[\"train\"][i] = chunk_start_idx\n",
    "    return start_idx_dict\n",
    "\n",
    "\n",
    "def optimized_gen_start_indices(\n",
    "    random_sequences, val_clip_idx, clip_length, chunk_size, num_clips\n",
    "):\n",
    "    \"\"\"\n",
    "    Optimized function to generate a list of indices for training chunks while\n",
    "    excluding validation clips.\n",
    "\n",
    "    :param random_sequences: int np array; 108 x 20, giving the ordering of the\n",
    "                             108 training clips for the 20 different sequences\n",
    "    :param val_clip_idx:     list of integers indicating the 15 clips to be used\n",
    "                             for validation\n",
    "    :param clip_length:      clip length in frames (5s*30frames/s = 150 frames)\n",
    "    :param chunk_size:       temporal chunk size per sample in frames (50)\n",
    "    :param num_clips:        total number of training clips (108)\n",
    "    :return: dict; with keys train, validation, and test, and index list as\n",
    "             values\n",
    "    \"\"\"\n",
    "    val_clip_set = set(val_clip_idx)\n",
    "    val_start_idx = list(\n",
    "        np.linspace(\n",
    "            0, clip_length * (len(val_clip_idx) - 1), len(val_clip_idx), dtype=int\n",
    "        )\n",
    "    )\n",
    "\n",
    "    start_idx_dict = {\"train\": {}, \"validation\": val_start_idx, \"test\": [0]}\n",
    "\n",
    "    for sequence_index in range(random_sequences.shape[1]):\n",
    "        start_idx = 0\n",
    "        current_idx = 0\n",
    "        seq_start_idx = []\n",
    "        seq_length = []\n",
    "\n",
    "        for clip_index in random_sequences[:, sequence_index]:\n",
    "            if clip_index in val_clip_set:\n",
    "                length = current_idx - start_idx\n",
    "                if length > 0:\n",
    "                    seq_start_idx.append(start_idx)\n",
    "                    seq_length.append(length)\n",
    "                start_idx = current_idx + clip_length\n",
    "            current_idx += clip_length\n",
    "\n",
    "        # Handling the last segment\n",
    "        length = current_idx - start_idx\n",
    "        if length > 0:\n",
    "            seq_start_idx.append(start_idx)\n",
    "            seq_length.append(length)\n",
    "\n",
    "        chunk_start_idx = [\n",
    "            idx\n",
    "            for start, length in zip(seq_start_idx, seq_length)\n",
    "            for idx in range(start, start + length - chunk_size + 1, chunk_size)[:-1]\n",
    "        ]\n",
    "        start_idx_dict[\"train\"][sequence_index] = chunk_start_idx\n",
    "\n",
    "    return start_idx_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_movies_dict = get_all_movie_combinations(movies[\"train\"], movies[\"test\"], movies[\"random_sequences\"], None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_indices = gen_start_indices(\n",
    "    movies[\"random_sequences\"],\n",
    "    all_movies_dict[\"val_clip_idx\"],\n",
    "    CLIP_LENGTH,\n",
    "    50,\n",
    "    NUM_CLIPS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_indices_opt = optimized_gen_start_indices(random_sequences, all_movies_dict[\"val_clip_idx\"], CLIP_LENGTH, 150, NUM_CLIPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuronData:\n",
    "    def __init__(\n",
    "        self,\n",
    "        eye,\n",
    "        group_assignment,\n",
    "        key,\n",
    "        responses_final,\n",
    "        roi_coords,\n",
    "        roi_ids,\n",
    "        scan_sequence_idx,\n",
    "        stim_id,\n",
    "        traces,\n",
    "        tracestimes,\n",
    "        random_sequences,\n",
    "        val_clip_idx,\n",
    "        num_clips,\n",
    "        clip_length,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Boilerplate class to store neuron data. Added for backwards compatibility with Hoefling et al., 2022.\n",
    "        \"\"\"\n",
    "\n",
    "        self.eye = eye\n",
    "        self.group_assignment = group_assignment\n",
    "        self.key = key\n",
    "        self.responses_final = responses_final\n",
    "        self.roi_coords = roi_coords\n",
    "        self.roi_ids = roi_ids\n",
    "        self.scan_sequence_idx = scan_sequence_idx\n",
    "        self.stim_id = stim_id\n",
    "        self.traces = traces\n",
    "        self.tracestimes = tracestimes\n",
    "        self.clip_length = clip_length\n",
    "        self.num_clips = num_clips\n",
    "        self.random_sequences = random_sequences\n",
    "        self.val_clip_idx = val_clip_idx\n",
    "\n",
    "    #! this has to become a regular method in the future\n",
    "    @property\n",
    "    def response_dict(self):\n",
    "        num_neurons = self.responses_final.shape[0]\n",
    "        movie_ordering = (\n",
    "            np.arange(self.num_clips)\n",
    "            if len(self.random_sequences) == 0\n",
    "            else self.random_sequences[:, self.scan_sequence_idx]\n",
    "        )\n",
    "\n",
    "        if self.stim_id == 0:\n",
    "            responses_test = self.responses_final[:, : 10 * self.clip_length].T\n",
    "            responses_train = self.responses_final[:, 10 * self.clip_length :].T\n",
    "            test_responses_by_trial = None\n",
    "        else:\n",
    "            responses_test = np.zeros((5 * self.clip_length, num_neurons))\n",
    "            responses_train = np.zeros((self.num_clips * self.clip_length, num_neurons))\n",
    "            test_responses_by_trial = []\n",
    "            for roi in range(num_neurons):\n",
    "                tmp = np.vstack(\n",
    "                    (\n",
    "                        self.responses_final[roi, : 5 * self.clip_length],\n",
    "                        self.responses_final[\n",
    "                            roi, 59 * self.clip_length : 64 * self.clip_length\n",
    "                        ],\n",
    "                        self.responses_final[roi, 118 * self.clip_length :],\n",
    "                    )\n",
    "                )\n",
    "                test_responses_by_trial.append(tmp)\n",
    "                responses_test[:, roi] = np.mean(tmp, 0)\n",
    "                responses_train[:, roi] = np.concatenate(\n",
    "                    (\n",
    "                        self.responses_final[\n",
    "                            roi, 5 * self.clip_length : 59 * self.clip_length\n",
    "                        ],\n",
    "                        self.responses_final[\n",
    "                            roi, 64 * self.clip_length : 118 * self.clip_length\n",
    "                        ],\n",
    "                    )\n",
    "                )\n",
    "            test_responses_by_trial = np.asarray(test_responses_by_trial)\n",
    "\n",
    "        if self.stim_id == 0:\n",
    "            responses_val = np.zeros(\n",
    "                [len(self.val_clip_idx), self.clip_length, num_neurons]\n",
    "            )\n",
    "            for i, ind in enumerate(self.val_clip_idx):\n",
    "                responses_val[i] = responses_train[\n",
    "                    ind * self.clip_length : (ind + 1) * self.clip_length, :\n",
    "                ]\n",
    "        else:\n",
    "            responses_val = np.zeros(\n",
    "                [len(self.val_clip_idx) * self.clip_length, num_neurons]\n",
    "            )\n",
    "            inv_order = np.argsort(movie_ordering)\n",
    "            for i, ind1 in enumerate(self.val_clip_idx):\n",
    "                ind2 = inv_order[ind1]\n",
    "                responses_val[\n",
    "                    i * self.clip_length : (i + 1) * self.clip_length, :\n",
    "                ] = responses_train[\n",
    "                    ind2 * self.clip_length : (ind2 + 1) * self.clip_length, :\n",
    "                ]\n",
    "\n",
    "        response_dict = {\n",
    "            \"train\": torch.tensor(responses_train).to(torch.float),\n",
    "            \"validation\": torch.tensor(responses_val).to(torch.float),\n",
    "            \"test\": {\n",
    "                \"avg\": torch.tensor(responses_test).to(torch.float),\n",
    "                \"by_trial\": torch.tensor(test_responses_by_trial),\n",
    "            },\n",
    "        }\n",
    "\n",
    "        return response_dict\n",
    "\n",
    "    def transform_roi_mask(self, roi_mask):\n",
    "        roi_coords = np.zeros((len(self.roi_ids), 2))\n",
    "        for i, roi_id in enumerate(self.roi_ids):\n",
    "            single_roi_mask = np.zeros_like(roi_mask)\n",
    "            single_roi_mask[roi_mask == -roi_id] = 1\n",
    "            roi_coords[i] = self.roi2readout(single_roi_mask)\n",
    "        return roi_coords\n",
    "\n",
    "    def roi2readout(\n",
    "        self,\n",
    "        single_roi_mask,\n",
    "        roi_mask_pixelsize=2,\n",
    "        readout_mask_pixelsize=50,\n",
    "        x_offset=2.75,\n",
    "        y_offset=2.75,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Maps a roi mask of a single roi from recording coordinates to model\n",
    "        readout coordinates\n",
    "        :param single_roi_mask: 2d array with nonzero values indicating the pixels\n",
    "                of the current roi\n",
    "        :param roi_mask_pixelsize: size of a pixel in the roi mask in um\n",
    "        :param readout_mask_pixelsize: size of a pixel in the readout mask in um\n",
    "        :param x_offset: x offset indicating the start of the recording field in readout mask\n",
    "        :param y_offset: y offset indicating the start of the recording field in readout mask\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        pixel_factor = readout_mask_pixelsize / roi_mask_pixelsize\n",
    "        y, x = np.nonzero(single_roi_mask)\n",
    "        y_trans, x_trans = y / pixel_factor, x / pixel_factor\n",
    "        y_trans += y_offset\n",
    "        x_trans += x_offset\n",
    "        x_trans = x_trans.mean()\n",
    "        y_trans = y_trans.mean()\n",
    "        coords = np.asarray(\n",
    "            [\n",
    "                self.map_to_range(max=8, val=y_trans),\n",
    "                self.map_to_range(max=8, val=x_trans),\n",
    "            ],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        return coords\n",
    "\n",
    "    def map_to_range(self, max, val):\n",
    "        val = val / max\n",
    "        val = val - 0.5\n",
    "        val = val * 2\n",
    "        return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def natmov_dataloaders_v2(\n",
    "    movies_dictionary,\n",
    "    neuron_data_dictionary,\n",
    "    train_chunk_size: int = 50,\n",
    "    batch_size: int = 32,\n",
    "    seed: int = 42,\n",
    "):\n",
    "    # make sure movies and responses arrive as torch tensors!!!\n",
    "    rnd = np.random.RandomState(seed)  # make sure whether we want the validation set to depend on the seed\n",
    "\n",
    "    num_clips, clip_length = NUM_CLIPS, CLIP_LENGTH\n",
    "    val_clip_idx = list(rnd.choice(NUM_CLIPS, NUM_VAL_CLIPS, replace=False))\n",
    "\n",
    "    clip_chunk_sizes = {\n",
    "        \"train\": train_chunk_size,\n",
    "        \"validation\": clip_length,\n",
    "        \"test\": 5 * clip_length,\n",
    "    }\n",
    "    dataloaders = {\"train\": {}, \"validation\": {}, \"test\": {}}\n",
    "    # draw validation indices so that a validation movie can be returned!\n",
    "    random_sequences = movies_dictionary[\"random_sequences\"]\n",
    "    movies = get_all_movie_combinations(\n",
    "        movies_dictionary[\"train\"], movies_dictionary[\"test\"], random_sequences, val_clip_idx=val_clip_idx\n",
    "    )\n",
    "    start_indices = gen_start_indices(random_sequences, val_clip_idx, clip_length, train_chunk_size, num_clips)\n",
    "    for session_key, session_data in neuron_data_dictionary.items():\n",
    "        neuron_data = NeuronData(\n",
    "            **session_data,\n",
    "            random_sequences=random_sequences,  # Used together with the validation index to get the validation response in the corresponding dict\n",
    "            val_clip_idx=val_clip_idx,\n",
    "            num_clips=num_clips,\n",
    "            clip_length=clip_length,\n",
    "        )\n",
    "\n",
    "        if neuron_data.responses_train.shape[-1] == 0:\n",
    "            print(\"skipped: {}\".format(session_key))\n",
    "            break\n",
    "        for fold in [\"train\", \"validation\", \"test\"]:\n",
    "            if not (hasattr(neuron_data, \"roi_coords\")):\n",
    "                neuron_data.roi_mask = []\n",
    "            dataloaders[fold][session_key] = get_movie_dataloader(\n",
    "                movies[neuron_data.eye][fold],\n",
    "                neuron_data.response_dict[fold],\n",
    "                neuron_data.roi_ids,\n",
    "                neuron_data.roi_coords,\n",
    "                neuron_data.group_assignment,\n",
    "                neuron_data.scan_sequence_idx,\n",
    "                fold,\n",
    "                clip_chunk_sizes[fold],\n",
    "                start_indices[fold],\n",
    "                batch_size,\n",
    "            )\n",
    "\n",
    "    return dataloaders"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
